{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_encoder import PromptEncoder, TwoWayTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2097152\n",
      "[ 412571  526511 1085798 1335781  538763  403005 1220542  351026  327143\n",
      "  740162]\n",
      "tensor([[ 23],\n",
      "        [ 17],\n",
      "        [ 34],\n",
      "        [ 67],\n",
      "        [113],\n",
      "        [ 76],\n",
      "        [ 63],\n",
      "        [ 54],\n",
      "        [123],\n",
      "        [ 22]])\n",
      "torch.Size([1, 30, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seg = torch.ones(1,128,128,128)\n",
    "l = len(torch.where(seg == 1)[0])\n",
    "print(l)\n",
    "sample = np.random.choice(np.arange(l), 10, replace=True) # 從範圍為 [0, l) 的整數中隨機選取 10 個數字（可能有重複）\n",
    "print(sample)\n",
    "x = torch.where(seg == 1)[1][sample].unsqueeze(1)\n",
    "y = torch.where(seg == 1)[3][sample].unsqueeze(1)\n",
    "z = torch.where(seg == 1)[2][sample].unsqueeze(1)\n",
    "print(z)\n",
    "point_coord = torch.cat([x, y, z], dim=1).unsqueeze(1).float() \n",
    "\n",
    "foo = torch.randn(1,20,3)\n",
    "point_coord = point_coord.transpose(0,1)\n",
    "point_coord = torch.cat([point_coord,foo],dim=1)\n",
    "print(point_coord.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "送進transformer的三個參數image_embeddings, image_pe, point_coord torch.Size([1, 256, 32, 32, 32]) torch.Size([1, 256, 32, 32, 32]) torch.Size([1, 1, 1, 30, 3])\n",
      "===init===\n",
      "image_embedding init torch.Size([1, 256, 32, 32, 32])\n",
      "point_coord init torch.Size([1, 1, 1, 30, 3])\n",
      "\n",
      "point_embedding after grid sample torch.Size([1, 256, 1, 1, 30])\n",
      "point_pe after grid sample torch.Size([1, 256, 1, 1, 30])\n",
      "\n",
      "        之所以維度由[1,256,32,32,32]變成[1,256,1,1,30]，是因為point_coord [1,1,1,30,3]中包含了30個xyz的座標(已正規化到-1~1之間)\n",
      "        定位了在image_embedding中的30個位置(維度中為32的D*H*W)，並對原始在對應image_embedding空間上的特徵進行插值(僅限這30個點)\n",
      "        因此結果會是[1,256,1,1,30]，最後一個維度代表其中某一個通道在這30個點中的特徵值\n",
      "        \n",
      "\n",
      "        接下來squeeze去除1維度\n",
      "        \n",
      "point_embedding after squeeze torch.Size([1, 256, 30])\n",
      "point_pe after squeeze torch.Size([1, 256, 30])\n",
      "\n",
      "        permute後, 現在我們有包含了點座標資訊的point_embedding特徵以及包含了點座標資訊的point_pe(一個固定的位置編碼矩陣)\n",
      "        \n",
      "point_embedding after permute torch.Size([1, 30, 256])\n",
      "point_pe after permute torch.Size([1, 30, 256])\n",
      "\n",
      "        把沒有經過給定點插植特徵的原始資料也做flatten & permute\n",
      "        \n",
      "image_embedding after flatten & permute torch.Size([1, 32768, 256])\n",
      "image_pe after flatten & permute torch.Size([1, 32768, 256])\n",
      "\n",
      "        image_embedding\t[1, 32768, 256]\n",
      "        image_pe    [1, 32768, 256]\n",
      "        point_embedding\t[1, 30, 256]\n",
      "        point_pe    [1, 30, 256]\n",
      "        全都丟進transformer block\n",
      "        \n",
      "transformer回傳 torch.Size([1, 32768, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 32, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo_feature = torch.randn(1,256,32,32,32) # 1, 256, ?, ?, ?\n",
    "prompt_encoder = PromptEncoder(transformer=TwoWayTransformer(depth=2,\n",
    "                                                                 embedding_dim=256,\n",
    "                                                                 mlp_dim=2048,\n",
    "                                                                 num_heads=8))\n",
    "prompt_encoder.to(\"cpu\")\n",
    "patch_size=128\n",
    "ans = prompt_encoder(foo_feature, point_coord, [patch_size, patch_size, patch_size]) # ?, [1,30,3], [128,128,128]\n",
    "\n",
    "ans.size() # 1, 32, 32, 32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
